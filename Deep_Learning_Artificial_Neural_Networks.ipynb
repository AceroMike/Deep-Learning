{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning: Artificial Neural Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/xJdu7ZRveg5sYqbvi6yo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AceroMike/Deep-Learning/blob/main/Deep_Learning_Artificial_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuak1BqcPd_m"
      },
      "source": [
        "# Imports\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "\r\n",
        "# Data\r\n",
        "from tensorflow.keras.datasets import mnist\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fpwl4bGPplM"
      },
      "source": [
        "In this notebook we will be building Dense Neural Networks. If you are unfamiliar with neural networks, conceptually, they are not to hard to understand. Think about models layered on each other. That is, the first model provides the inputs for the second, the second to the third, and so on. This is a Sequential model which we will model here. A dense model implies that the layers are fully connected so each node/feature gives input to each other feature in the 2nd model. Here we will work with the mnist dataset which is a common dataset to practice Deep learning. This dataset contains handwritted images of integers. Therfore, we will try to predict the number. \r\n",
        "\r\n",
        "The first step is to load the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5VviE9oQVlb",
        "outputId": "31a27486-c95d-43fe-faba-31711528411b"
      },
      "source": [
        "# Loading and Preprocessing the Data\r\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "input_dim = 784  # 28*28\r\n",
        "output_dim = nb_classes = 10\r\n",
        "batch_size = 128\r\n",
        "nb_epoch = 20\r\n",
        "\r\n",
        "# We will be working on a sample\r\n",
        "X_train = X_train.reshape(60000, input_dim)\r\n",
        "X_test = X_test.reshape(10000, input_dim)\r\n",
        "X_train = X_train.astype('float32')\r\n",
        "X_test = X_test.astype('float32')\r\n",
        "\r\n",
        "# This normalizes the data\r\n",
        "X_train /= 255\r\n",
        "X_test /= 255"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUIuU_KFQ3dz"
      },
      "source": [
        "The `input dimension` is the size of each picture which is 28 * 28 pixels. The `output dimension` is ten because the numbers in the data set include 0-9, or 10 number total. The `nb epoch` tells us how many times the model is going to itterate through the entire data set. \r\n",
        "\r\n",
        "Now we want to one hot encode our target variable. Right now, our target variable tells us the actual number. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BFXiIOAR4Sl",
        "outputId": "3a13e681-0ed8-4116-ab8a-59d2872e38cd"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZGrgluHR7Eg"
      },
      "source": [
        "So the first observation is a 5. Now let's one hot encode by using the `to_categorical()` function from the `keras.utils` module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OizFVLKPR5x7"
      },
      "source": [
        "Y_train = to_categorical(y_train, nb_classes)\r\n",
        "Y_test = to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58mg9RPbSIyU",
        "outputId": "a33ec915-b679-41d0-93da-4209172e3471"
      },
      "source": [
        "Y_train[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CTuE8dPSL22"
      },
      "source": [
        "If you look at the array we now see a 1 in the 6th spot, which corresponds to the number 5. Don't believe me? Let's look at some visualizations before modeling the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "qSRZGDbxSLEv",
        "outputId": "2715977c-50a7-49f6-a61b-33cd85ba624f"
      },
      "source": [
        "plt.figure(figsize=(20,5))\r\n",
        "\r\n",
        "plt.subplot(141)\r\n",
        "plt.imshow(X_train[0].reshape(28,28), cmap=\"gray\")\r\n",
        "plt.title(\"Label of the image: {}\".format(y_train[0]))\r\n",
        "\r\n",
        "plt.subplot(142)\r\n",
        "plt.imshow(X_train[1].reshape(28,28), cmap=\"gray\")\r\n",
        "plt.title(\"Label of the image: {}\".format(y_train[1]))\r\n",
        "\r\n",
        "plt.subplot(143)\r\n",
        "plt.imshow(X_train[2].reshape(28,28), cmap=\"gray\")\r\n",
        "plt.title(\"Label of the image: {}\".format(y_train[2]))\r\n",
        "\r\n",
        "plt.subplot(144)\r\n",
        "plt.imshow(X_train[3].reshape(28,28), cmap=\"gray\")\r\n",
        "plt.title(\"Label of the image: {}\".format(y_train[3]))\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW5rg5R9ShSS"
      },
      "source": [
        "Et Voila, now we can model. The first step in modeling an ANN is to decide how many layers you want the model to have as well as how many nodes each layer will have. We will look at 2 different specifications to compare the performance of each. First, we will specify the model as follows:\r\n",
        "\r\n",
        "This ANN will consist of one hidden layer and one output layer. All of the hidden layers will be dense (In later notebooks I will look at others). The first layer and the second layer should have neuron sizes of 32 and 16, respectively.\r\n",
        "\r\n",
        "The layers of an ANN starts with the input layer, followed by as many hidden layers as you please, and ending with the output layer. In this example the output layer will have 10 neurons to correspond to the 10 digits. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4BMcM7_SfNz"
      },
      "source": [
        "# Initializing the model\r\n",
        "model = Sequential()\r\n",
        "#Input Layer\r\n",
        "model.add(Dense(32, input_shape=(784,), activation='relu'))\r\n",
        "#Hidden Layer\r\n",
        "model.add(Dense(16, input_shape=(784,), activation='relu'))\r\n",
        "#Output Layer\r\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0E49BACUpMT"
      },
      "source": [
        "The activation function, is the function that the model tries to minimize. Here we use the 'relu' or Rectified Linear Unit. For the output layer we use softmax. In later notebooks I will go more in depth to discuss but the purpose of this notebook is just to see ANN in action. Let's take a look at the summary of the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgvDYX5mVIjH",
        "outputId": "ae950985-5e77-43f0-f725-3274ae11874c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 25,818\n",
            "Trainable params: 25,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXS9tO6PVLpC"
      },
      "source": [
        "Our model now has 3 dense layers and is estimating a total of 25,818 parameters. Now let's compile the model. When compiling the model we have to decide 3 things: \r\n",
        "- What optimizer will be used in training\r\n",
        "- What loss function will be used\r\n",
        "- How will we measure training performance. \r\n",
        "\r\n",
        "We will not go in depth, yet, in the different ways. But will optimize using Stochastic Gradient Descent, our loss function will be Categorical Cross Entropy and our metric will be accuracy since we want to see how well our model predicts the number of the image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq8F9cuLVJte"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imnjeIjWWUdC"
      },
      "source": [
        "Now we can train the model using the usual `.fit()` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E09pVgaWRhV",
        "outputId": "7ef9fba5-2530-4080-cba4-d5263e9c6a88"
      },
      "source": [
        "#Fitting the model\r\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 2.1288 - accuracy: 0.2506 - val_loss: 1.2652 - val_accuracy: 0.6254\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.0630 - accuracy: 0.6946 - val_loss: 0.6635 - val_accuracy: 0.8160\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.6266 - accuracy: 0.8215 - val_loss: 0.4883 - val_accuracy: 0.8637\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.8673 - val_loss: 0.4085 - val_accuracy: 0.8856\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4095 - accuracy: 0.8850 - val_loss: 0.3630 - val_accuracy: 0.8983\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3693 - accuracy: 0.8972 - val_loss: 0.3380 - val_accuracy: 0.9063\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.9021 - val_loss: 0.3192 - val_accuracy: 0.9087\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.9040 - val_loss: 0.3080 - val_accuracy: 0.9107\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.9099 - val_loss: 0.2963 - val_accuracy: 0.9152\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3008 - accuracy: 0.9142 - val_loss: 0.2865 - val_accuracy: 0.9182\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2840 - accuracy: 0.9185 - val_loss: 0.2788 - val_accuracy: 0.9195\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2865 - accuracy: 0.9179 - val_loss: 0.2718 - val_accuracy: 0.9220\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.9228 - val_loss: 0.2656 - val_accuracy: 0.9232\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2641 - accuracy: 0.9241 - val_loss: 0.2587 - val_accuracy: 0.9236\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.9263 - val_loss: 0.2540 - val_accuracy: 0.9261\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2552 - accuracy: 0.9265 - val_loss: 0.2471 - val_accuracy: 0.9288\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.9293 - val_loss: 0.2454 - val_accuracy: 0.9298\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2386 - accuracy: 0.9312 - val_loss: 0.2361 - val_accuracy: 0.9312\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2332 - accuracy: 0.9323 - val_loss: 0.2307 - val_accuracy: 0.9332\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2286 - accuracy: 0.9329 - val_loss: 0.2263 - val_accuracy: 0.9338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd7f6ab5a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX0Vvsm0Wwbi"
      },
      "source": [
        "The accuracy column here tells us only how the data predicts itself, that is, the test data, the val_accuracy is the one that tells us how it does outside of the model As we can see, with each iteration, the accuracy of the model increases. Now let's look at another specification so we can compare. Now we will specify the model as follows:\r\n",
        "\r\n",
        "This ANN should have four hidden layers and one output layer. All of the layers should be dense. The neuron numbers for the layers should be 1024, 512, 256, 128, and 64."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbAR-KPsWcux"
      },
      "source": [
        "model = Sequential()\r\n",
        "#Input Layer\r\n",
        "model.add(Dense(1024, input_shape=(784,), activation='relu'))\r\n",
        "#Hidden Layer 1\r\n",
        "model.add(Dense(512, input_shape=(784,), activation='relu'))\r\n",
        "#Hidden Layer 2\r\n",
        "model.add(Dense(256, input_shape=(784,), activation='relu'))\r\n",
        "#Hidden Layer 3\r\n",
        "model.add(Dense(128, input_shape=(784,), activation='relu'))\r\n",
        "#Hidden Layer 4\r\n",
        "model.add(Dense(64, input_shape=(784,), activation='relu'))\r\n",
        "#Output Layer\r\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzmBXntVX5PS"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_UtGGggX_wp"
      },
      "source": [
        "Since we are estimating more parameters, the code will take longer to run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAVX_DXgX75B",
        "outputId": "bee77dfe-46ee-422f-e6bd-e0e3941d12c0"
      },
      "source": [
        "#Fitting the model\r\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=128, epochs=20, verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 12s 24ms/step - loss: 1.8538 - accuracy: 0.4697 - val_loss: 0.4665 - val_accuracy: 0.8785\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.4217 - accuracy: 0.8835 - val_loss: 0.3075 - val_accuracy: 0.9089\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.2918 - accuracy: 0.9162 - val_loss: 0.2430 - val_accuracy: 0.9302\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.2397 - accuracy: 0.9301 - val_loss: 0.2121 - val_accuracy: 0.9376\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.2092 - accuracy: 0.9393 - val_loss: 0.1914 - val_accuracy: 0.9441\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1844 - accuracy: 0.9465 - val_loss: 0.1741 - val_accuracy: 0.9487\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1699 - accuracy: 0.9500 - val_loss: 0.1880 - val_accuracy: 0.9448\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1496 - accuracy: 0.9576 - val_loss: 0.1470 - val_accuracy: 0.9557\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1374 - accuracy: 0.9600 - val_loss: 0.1350 - val_accuracy: 0.9592\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1263 - accuracy: 0.9640 - val_loss: 0.1406 - val_accuracy: 0.9580\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1182 - accuracy: 0.9662 - val_loss: 0.1233 - val_accuracy: 0.9635\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.1081 - accuracy: 0.9685 - val_loss: 0.1181 - val_accuracy: 0.9639\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0998 - accuracy: 0.9710 - val_loss: 0.1099 - val_accuracy: 0.9670\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0899 - accuracy: 0.9743 - val_loss: 0.1175 - val_accuracy: 0.9651\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0858 - accuracy: 0.9754 - val_loss: 0.0999 - val_accuracy: 0.9690\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0798 - accuracy: 0.9780 - val_loss: 0.0971 - val_accuracy: 0.9698\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0731 - accuracy: 0.9798 - val_loss: 0.0953 - val_accuracy: 0.9697\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 11s 24ms/step - loss: 0.0698 - accuracy: 0.9805 - val_loss: 0.0900 - val_accuracy: 0.9727\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0630 - accuracy: 0.9824 - val_loss: 0.0911 - val_accuracy: 0.9719\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 12s 25ms/step - loss: 0.0568 - accuracy: 0.9843 - val_loss: 0.0981 - val_accuracy: 0.9700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd7f6ab44e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfiFCHXpYMCn"
      },
      "source": [
        "As we see, we quickly surpass the accuracy of the first model. This will not always be the case although, unlike shallow models (models that are not deep) We can more easily increase the number of features without worrying (as much) about overfitting because ANN models don't begin to overfit as quickly, But still we bigin to see the model overfit more with each iteration. We also see that we minimize loss the most with this model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ3qB8vpX9di"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}